- 不同语言、模型、推理框架的速度对比

# 分类任务

- ImageNet 预训练模型
- ImageSize 224*224
- 统计100张图片的总耗时（cpu i7-10700 2.9G）

语言|模型|模型文件大小MB|计算量 GFlops| 推理框架 |耗时 ms|备注
---|---|---|---|---|---|---
python|YS|19.4| 12.5          | ONNX     | 50 |
python|YS-onnx|19.4| 12.5          | OpenVINO | 19 |
python|YS-IR|19.4| 12.5          | OpenVINO | 19 |
python|YM|60.1|41.6|ONNX|110|
python|YM-onnx|60.1|41.6|OpenVINO|26|
python|YM-IR|60.1|41.6|OpenVINO|27|
python|YL|138|98.7|ONNX|221|
 python | YL-onnx | 138            | 98.7          | OpenVINO | 39      |
 python | YL-IR   | 138            | 98.7          | OpenVINO | 42      |
||||||
||||||
CPP|YS-onnx|19.4| 12.5          |OpenVINO|13|
CPP|YM-onnx|60.1|41.6|OpenVINO|22|
CPP|YL-onnx|138|98.7|OpenVINO|35|
        |         |                |               |          |         |      
 CPP    | YS-onnx |                |               | ONNX     ||
CPP|YM-onnx|||ONNX||
CPP|YL-onnx|||ONNX||

- python 使用openvino推理，相比onnx会显著加快，但是使用openvino做模型导出速度没有提升，可能还需要做更进一步量化（待实验）

## 示例代码

```python
# python 使用onnx推理
import cv2
import cv2.dnn
from torchvision import transforms
from PIL import Image

img_trans = transforms.Compose([
    transforms.Resize(size=224),
    transforms.CenterCrop(size=(224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=torch.tensor([0.,0.,0.]), std=torch.tensor([1.,1.,1.]))
])
model = cv2.dnn.readNetFromONNX(onnx_pth)
img_mat = cv2.imread(img_pth)
blob = img_trans(Image.fromarray(cv2.cvtColor(img_mat, cv2.COLOR_BGR2RGB))).unsqueeze(0)
model.setInput(blob.numpy())
outputs = model.forward()
```



```python
# python 使用opevino推理
import cv2
import cv2.dnn
from torchvision import transforms
from PIL import Image
import openvino as ov

core = ov.Core()
# model = core.read_model(model=r"D:\share_dir\repository_check\workdir_v8_0325\check_package\use_large_model5\weights\model.xml")  # 使用IR模型并没有速度提升
model = core.read_model(model=onnx_pth)
compiled_model = core.compile_model(model=model, device_name="CPU")
output_layer = compiled_model.output(0)
# 如果使用torchvision的前处理可以实现推理结果一致，但是速度会慢几ms
# img_mat = cv2.imread(img_pth)
# input_img = img_trans(Image.fromarray(cv2.cvtColor(img_mat, cv2.COLOR_BGR2RGB))).unsqueeze(0).numpy()
# 使用opencv的前处理 精度会差一点点 但是速度会快几ms
img_mat = cv2.imread(img_pth)
img_mat = img_mat.astype(np.float32)
input_img = cv2.dnn.blobFromImage(img_mat, 1.0/255, (224,224), 0.0, swapRB=True, ddepth=cv2.CV_32F)
result_infer = compiled_model([input_img])[output_layer]

```





# 检测任务

- COCO预训练模型
- ImageSize 640*640
- 统计100张图片的总耗时（cpu i7-10700 2.9G）
语言|模型|模型文件大小MB|计算量 GFlops| 推理框架 |耗时|备注
---|---|---|---|---|---|---
python|YS||89GFLops| ONNX     | 100ms |
python|YM|||ONNX||
python|YL|||ONNX||
CPP|YS|||ONNX||
CPP|YM|||ONNX||
CPP|YL|||ONNX||
python|YS-onnx||89GFLops|OpenVINO|100ms|
python|YS-IR|||OpenVINO||
||||||

