# 核心部分

- 网络结构
- 损失函数
- 参数优化算法
- 如何处理过拟合等中间问题

- 如何解决过拟合欠拟合的问题：
  - 原因是：数据复杂度与模型复杂度不相匹配
  - 数据方面：多采集数据、数据增强
  - 模型方面：选择更简单的模型（配合验证集）、正则项、DropOut
  - 训练策略方面：交叉验证、提前终止EarlyStop

- L1 & L2 正则化：
  - L1 更倾向于产生稀疏解，适用于**特征选择**
  - L2 更倾向于产生小的非零值，适用于**优化问题**

- DropOut
  - 在训练过程中随机删除一些神经元（即将其权重设为0）
  - **只用在训练期间，不用在测试期间**；
  - 本质是Bagging集成学习，平均化的作用；
  - 减少神经元之间复杂的关系
  - 优缺点：
    - 优点：可以有效的降低过拟合；简单方便；
    - 缺点：降低训练效率（因为多了一个计算是否置零的随机）；损失函数不够明确（因为部分节点直接置零导致最后的损失函数有差异）；

- 梯度消失和梯度爆炸
  - 梯度消失：反向链式传播过程中，梯度<1,累乘过程中消失；现象：
  - 梯度爆炸：权重初始化的值过大，网络层数；现象：训练过程不稳定不收敛，溢出
  - 解决方法：
    - 调节学习率
    - 梯度剪切：（针对梯度爆炸）限制梯度最大值
    - ReLU激活函数：LeakyReLU
    - BatchNorm： 可以让训练过程更稳定
      - ![BatchNorm](../image_resources/BatchNorm.png)
      - 先规范化到 均值为0 方差为1，然后再进行缩放
      - 所以 BN层里可以有可训练的参数，缩放参数与平移参数
    - 残差结构

## 优化算法

### 梯度下降
### 动量法
### AdaGrad
### RMSProp Adadelta
### Adam
### AdamW

# ResNet

# 可变形卷积

- 卷积不再是计算相邻区域，而是多算 x y 方向的偏移量之后的卷积
- 使得卷积更多集中计算前景区域
- 适用于有很多遮挡物的场景；

# 可变形注意力机制

- 因为注意力机制，在计算`self-attention`时计算量特别大，因为要和每个头两两计算注意力；
- 提出可变形注意力，即多预测两个值，只关注4个头之间的注意力，从而降低计算量；

# SqueezeNet

# DarkNet

# CSPNet

# ViT

- `CNN` 卷积是通过卷积核提取区域特征，通过多层堆叠获取更大的感受野，从而获得全局语义信息；
- `Transformer` 第一步使用CNN提取区域特 m征，然后用`Self-Attention`机制提取不同区域之间的关系，从而获得全局语义信息；
- `注意力机制`是通过`Q K V` 三个矩阵实现的，其中 `Q K V` 分别是通过`MLP`全连接网络，从`Token`经过`Embedding` 得到的
- `多头注意力机制` 是将 `Q K V` 的特征维度，拆分成多份，每个头训练一部分，最好`concate`起来；

# DINO

- https://medium.com/@anuj.dutt9/emerging-properties-in-self-supervised-vision-transformers-dino-paper-summary-4c7a6ed68161

- Self-DIstillation with NO Labels
- 基于对比学习  Contrastive Learning

- 训练方法
  - 多重裁剪策略：采用多种数据集增强技术，同一张图产生多种变形后的视角；
  - Local-to-Global Learning：所有裁剪的图传入 Student Model ，Global view 传入 Teacher Model；<font color=red>让Student Model学习 Local 图 与 Global 图的关系？？？</font>
  - 损失：最小化 Teacher Model 和 Student Model 之间的， 针对同一张图片，不同视角下的表征偏差，所以不需要标签；
  - ![image-20240617103652196](..\image_resources\image-20240617103652196.png)
  - <img src="..\image_resources\image-20240617103652196.png" style="zoom:80%;">
  - Teacher Model 和 Student Model 有相同的结构，但是不同的参数；
  - 传入两个模型的是，同一张图片的不同随机增强的结果；
  - Teacher Model 的参数 是根据 Student Model 参数的指数滑动平均（ema）结果进行更新的，Student Model 是根据反向传播更新的；
  - 

# DCN

- Dual-channel Convolutional Network  基于双通道的卷积神经网络