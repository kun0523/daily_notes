# ResNet



# SqueezeNet



# DarkNet



# CSPNet



# ViT





# DINO

- https://medium.com/@anuj.dutt9/emerging-properties-in-self-supervised-vision-transformers-dino-paper-summary-4c7a6ed68161

- Self-DIstillation with NO Labels
- 基于对比学习  Contrastive Learning

- 训练方法
  - 多重裁剪策略：采用多种数据集增强技术，同一张图产生多种变形后的视角；
  - Local-to-Global Learning：所有裁剪的图传入 Student Model ，Global view 传入 Teacher Model；<font color=red>让Student Model学习 Local 图 与 Global 图的关系？？？</font>
  - 损失：最小化 Teacher Model 和 Student Model 之间的， 针对同一张图片，不同视角下的表征偏差，所以不需要标签；
  - ![image-20240617103652196](..\image_resources\image-20240617103652196.png)
  - <img src="..\image_resources\image-20240617103652196.png" style="zoom:80%;">
  - Teacher Model 和 Student Model 有相同的结构，但是不同的参数；
  - 传入两个模型的是，同一张图片的不同随机增强的结果；
  - Teacher Model 的参数 是根据 Student Model 参数的指数滑动平均（ema）结果进行更新的，Student Model 是根据反向传播更新的；
  - 

# DCN

- Dual-channel Convolutional Network  基于双通道的卷积神经网络